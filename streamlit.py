{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d230d74-d3c3-4d12-a2b7-3d0dd98922fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data (punkt, stopwords, wordnet)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load saved models and vectorizer\n",
    "model = joblib.load('naive_bayes_model.joblib')\n",
    "tfidf_vectorizer_loaded = joblib.load('tfidf_vectorizer.joblib')\n",
    "\n",
    "# Initialize the lemmatizer, stemmer, and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = LancasterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Stemming and Lemmatization\n",
    "    preprocessed_text = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        for word in sentence:\n",
    "            if word not in stop_words:\n",
    "                # Apply lemmatization followed by stemming\n",
    "                lemmatized_word = lemmatizer.lemmatize(word)\n",
    "                stemmed_word = stemmer.stem(lemmatized_word)\n",
    "                preprocessed_text.append(stemmed_word)\n",
    "\n",
    "    return ' '.join(preprocessed_text)\n",
    "\n",
    "# Function for making predictions and displaying results\n",
    "def predict_and_display(reviews):\n",
    "    # Preprocess the reviews\n",
    "    preprocessed_reviews = [preprocess_text(review) for review in reviews]\n",
    "\n",
    "    # Transform the preprocessed reviews using the vectorizer\n",
    "    transformed_reviews = tfidf_vectorizer_loaded.transform(preprocessed_reviews)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = model.predict(transformed_reviews)\n",
    "\n",
    "    # Display results\n",
    "    for i, review in enumerate(reviews):\n",
    "        st.write(f\"Review {i+1}: {review}\")\n",
    "        st.write(f\"Predicted Sentiment: {'Positive' if predictions[i] == 1 else 'Negative'}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    st.title(\"Product Review Sentiment Analysis\")\n",
    "    \n",
    "    st.sidebar.title(\"Options\")\n",
    "    option = st.sidebar.selectbox(\"Choose how to input data\", [\"Enter text\", \"Upload file\"])\n",
    "    if option == \"Enter text\":\n",
    "\n",
    "    # Single review input\n",
    "        user_input = st.text_input(\"Enter review text:\")\n",
    "\n",
    "     # Check if the input is not empty\n",
    "            if st.button('Predict'):\n",
    "            if user_input:  # Check if the input is not empty\n",
    "        reviews = [user_input]  # Treat the user input as a review body\n",
    "        predict_and_display(reviews)  # Single review prediction\n",
    "    else:\n",
    "        st.error(\"Please enter a review for prediction.\")\n",
    "else:\n",
    "    # File upload option\n",
    "    uploaded_file = st.file_uploader(\"Choose a file (CSV format)\", type=[\"csv\"])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        if 'review_body' in df.columns:\n",
    "            reviews = df['review_body'].tolist()\n",
    "            predict_and_display(reviews)\n",
    "        else:\n",
    "            st.error(\"The file does not contain the 'review_body' column.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
